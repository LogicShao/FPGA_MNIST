#!/usr/bin/env python
import argparse
import json
import os

import numpy as np
import torch

from models import TinyLeNet


def to_hex32(value):
    return f"{(value & 0xFFFFFFFF):08X}"


def write_mem(path, values, depth=None):
    if depth is None:
        depth = len(values)
    with open(path, "w", newline="\n") as f:
        for i in range(depth):
            v = values[i] if i < len(values) else 0
            f.write(to_hex32(int(v)) + "\n")


def write_rom(path, module_name, mem_filename, depth, addr_width):
    with open(path, "w", newline="\n") as f:
        f.write("// Auto-generated by quantize_bias.py\n")
        f.write(f"module {module_name} #(\n")
        f.write(f"    parameter integer ADDR_WIDTH = {addr_width},\n")
        f.write("    parameter integer DATA_WIDTH = 32,\n")
        f.write(f"    parameter integer DEPTH = {depth},\n")
        f.write(f"    parameter MEM_FILE = \"{mem_filename}\"\n")
        f.write(") (\n")
        f.write("    input  wire                    clk,\n")
        f.write("    input  wire [ADDR_WIDTH-1:0]   addr,\n")
        f.write("    output reg  signed [DATA_WIDTH-1:0] q\n")
        f.write(");\n\n")
        f.write("    (* ramstyle = \"M9K\" *) reg [DATA_WIDTH-1:0] mem [0:DEPTH-1];\n\n")
        f.write("    initial begin\n")
        f.write("        $readmemh(MEM_FILE, mem);\n")
        f.write("    end\n\n")
        f.write("    always @(posedge clk) begin\n")
        f.write("        q <= $signed(mem[addr]);\n")
        f.write("    end\n\n")
        f.write("endmodule\n")


def main():
    parser = argparse.ArgumentParser(description="Quantize biases to int32 using effective scales.")
    parser.add_argument("--quant-params", default="model_tools/quant_params.json")
    parser.add_argument("--out-dir", default="hardware/src/v1.1/rtl/weights")
    args = parser.parse_args()

    with open(args.quant_params, "r", encoding="utf-8") as f:
        params = json.load(f)

    model_path = params["model_path"]
    model = TinyLeNet()
    checkpoint = torch.load(model_path, map_location="cpu")
    state = checkpoint.get("model_state_dict", checkpoint)
    model.load_state_dict(state)
    model.eval()

    s_in = params["scales"]["s_in"]
    s_pool1 = params["scales"]["s_pool1"]
    s_pool2 = params["scales"]["s_pool2"]
    s_fc1 = params["scales"]["s_fc1"]

    s_w1 = params["scales"]["s_w1"]
    s_w2 = params["scales"]["s_w2"]
    s_w3 = params["scales"]["s_w3"]
    s_w4 = params["scales"]["s_w4"]

    b1 = model.conv1.bias.detach().cpu().numpy()
    b2 = model.conv2.bias.detach().cpu().numpy()
    b3 = model.fc1.bias.detach().cpu().numpy()
    b4 = model.fc2.bias.detach().cpu().numpy()

    b1_q = np.round(b1 * (s_in * s_w1)).astype(np.int32)
    b2_q = np.round(b2 * (s_pool1 * s_w2)).astype(np.int32)
    b3_q = np.round(b3 * (s_pool2 * s_w3)).astype(np.int32)
    b4_q = np.round(b4 * (s_fc1 * s_w4)).astype(np.int32)

    os.makedirs(args.out_dir, exist_ok=True)

    files = [
        ("CONV1_BIASES_INT32", b1_q),
        ("CONV2_BIASES_INT32", b2_q),
        ("FC1_BIASES_INT32", b3_q),
        ("FC2_BIASES_INT32", b4_q),
    ]

    for name, values in files:
        depth = len(values)
        addr_width = max(1, (depth - 1).bit_length())
        depth_pow2 = 1 << addr_width
        mem_path = os.path.join(args.out_dir, f"{name}.mem")
        write_mem(mem_path, values.tolist(), depth_pow2)
        rom_path = os.path.join(args.out_dir, f"{name}_rom.v")
        write_rom(rom_path, f"rom_{name}", os.path.basename(mem_path), depth_pow2, addr_width)
        print(f"Wrote {mem_path} and {rom_path} (depth={depth_pow2}, used={depth})")


if __name__ == "__main__":
    main()
